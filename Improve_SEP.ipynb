{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/xb1Tzlj9K+DsdCv5s7Xb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/No1-JSPARK/ANN_Proejct_Proposal/blob/main/Improve_SEP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tZSV_3S7dat9"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KFzwxokdfbV",
        "outputId": "38d2a797-bcb2-4bc9-cfc4-8e842098fc31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Solving English')"
      ],
      "metadata": {
        "id": "eWsVXaXEdj1z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofd3q-RcdkaR",
        "outputId": "dec1251d-b86f-4b79-bf53-64477e5ea8d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Solving English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVFR9AKIeXYS",
        "outputId": "caf1d5b9-6d24-48d0-d7ef-fed8e5a75773"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 36.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 77.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 62.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aYwwN6Aec1_",
        "outputId": "24cfcc2f-f930-4280-9e68-0c374c2c13c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-transformers) (4.64.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 66.9 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.26.23-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 77.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch-transformers) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.1.1)\n",
            "Collecting botocore<1.30.0,>=1.29.23\n",
            "  Downloading botocore-1.29.23-py3-none-any.whl (10.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2 MB 43.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.23->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.23->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-transformers) (2022.9.24)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 61.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->pytorch-transformers) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=1c779c717a2b9a5a8687ddc115ddeabf106fab7a68314dd145f644e5475152c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.26.23 botocore-1.29.23 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "M0Mp4ONXdvyT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "klszISp1e_MD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./dataset/proc_train.tsv', delimiter='\\t')\n",
        "valid_df = pd.read_csv('./dataset/proc_val.tsv', delimiter='\\t')\n",
        "test_df = pd.read_csv(\"./dataset/test_2.csv\", encoding = 'cp1252')"
      ],
      "metadata": {
        "id": "sBC8f9JSfKat"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LNdWDwzqibKT",
        "outputId": "0ec1e7fe-be7c-4b56-ee2a-c7065242cf29"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  label\n",
              "0  This is the main motive for gossiping about we...      1\n",
              "1  The chemical industry denied that there were p...      0\n",
              "2  The ironic effect seems to be caused by the in...      1\n",
              "3  The partner only has two options. He can take ...      0\n",
              "4  An Egyptian sculpture no bigger than a person’...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6f7dfac-0a1e-4710-8356-73445fc788a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is the main motive for gossiping about we...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The chemical industry denied that there were p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The ironic effect seems to be caused by the in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The partner only has two options. He can take ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>An Egyptian sculpture no bigger than a person’...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6f7dfac-0a1e-4710-8356-73445fc788a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6f7dfac-0a1e-4710-8356-73445fc788a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6f7dfac-0a1e-4710-8356-73445fc788a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ru9nJdtVigkt",
        "outputId": "04c24e0f-deec-4ee4-9a36-dbd23646ec80"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  label\n",
              "0        In a sense, all competitions give feedback.      1\n",
              "1  Even under ideal circumstances, hunting these ...      1\n",
              "2  Among hunter-gatherers, animals are not only g...      1\n",
              "3                      But that’s not what happened.      1\n",
              "4  Consequently, any small difference in mental f...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-832d0b64-16df-4bda-a5b0-e088e4394937\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In a sense, all competitions give feedback.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Even under ideal circumstances, hunting these ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Among hunter-gatherers, animals are not only g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>But that’s not what happened.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Consequently, any small difference in mental f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-832d0b64-16df-4bda-a5b0-e088e4394937')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-832d0b64-16df-4bda-a5b0-e088e4394937 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-832d0b64-16df-4bda-a5b0-e088e4394937');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6tas5zIdnSs-",
        "outputId": "22f5a631-885d-4da5-db89-5135842956bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  label\n",
              "0  Regulations covering scientific experiments on...      1\n",
              "1  Subjects must give their informed, written con...      1\n",
              "2  Scientists who experiment on themselves can, f...      1\n",
              "3  They can also sidestep most of the ethical iss...      1\n",
              "4  Nonetheless, experimenting on oneself remains ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cea543d8-ae41-4563-9b7f-436af132c7c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regulations covering scientific experiments on...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subjects must give their informed, written con...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Scientists who experiment on themselves can, f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>They can also sidestep most of the ethical iss...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nonetheless, experimenting on oneself remains ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cea543d8-ae41-4563-9b7f-436af132c7c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cea543d8-ae41-4563-9b7f-436af132c7c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cea543d8-ae41-4563-9b7f-436af132c7c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Datasets(Dataset):\n",
        "  def __init__ (self, df):\n",
        "    self.df = df\n",
        "  \n",
        "  def __len__ (self):\n",
        "    return len(self.df)\n",
        "  \n",
        "  def __getitem__ (self, idx):\n",
        "    text = self.df.iloc[idx,0]\n",
        "    label = self.df.iloc[idx,1]\n",
        "    return text, label"
      ],
      "metadata": {
        "id": "zDK5LnXXnVfb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Datasets(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "XeAlW1oBn6Uu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = Datasets(valid_df)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "pIp54gxIo0l6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Datasets(test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "_X4xT5NLo_zk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_mYm4mGpRpj",
        "outputId": "5a041269-ec3b-43bc-c236-745b298d1808"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 257551.00B/s]\n",
            "100%|██████████| 433/433 [00:00<00:00, 179672.90B/s]\n",
            "100%|██████████| 440473133/440473133 [00:52<00:00, 8429940.60B/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "  if save_path == None:\n",
        "    return\n",
        "  state_dict = {'model_state_dict' : model.state_dict(), 'valid_loss' : valid_loss}\n",
        "  torch.save(state_dict, save_path)\n",
        "  ##print(f'Model save to ==> {save_path}')"
      ],
      "metadata": {
        "id": "uwTK8kkTqHJP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(load_path, model):\n",
        "  if load_path == None:\n",
        "    return\n",
        "  state_dict = torch.load(load_path, map_location=device)\n",
        "  print(f'Model loaded from <== {load_path}')\n",
        "  model.load_state_dict(state_dict['model_state_dict'])\n",
        "  return state_dict['valid_loss']"
      ],
      "metadata": {
        "id": "m_z5zE_Eq5kU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "  if save_path == None:\n",
        "    return\n",
        "  state_dict = {'train_loss_list' : train_loss_list,\n",
        "                'valid_loss_list' : valid_loss_list,\n",
        "                'global_steps_list' : global_steps_list}\n",
        "  torch.save(state_dict, save_path)\n",
        "  ##print(f'Model save to ==> {save_path}')"
      ],
      "metadata": {
        "id": "P_QKzctyQtkN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_metrics(load_path):\n",
        "  if load_path == None:\n",
        "    return\n",
        "  state_dict = torch.load(load_path, map_location = device)\n",
        "  print(f'Model loaded from <== {load_path}')\n",
        "  return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ],
      "metadata": {
        "id": "pCHrHUS5Rczy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          optimizer,\n",
        "          criterion=nn.BCELoss(),\n",
        "          num_epochs=5,\n",
        "          eval_every=len(train_loader)//2,\n",
        "          best_valid_loss=float(\"Inf\")):\n",
        "  \n",
        "  total_correct = 0.0\n",
        "  total_len = 0.0\n",
        "  running_loss = 0.0\n",
        "  valid_running_loss = 0.0\n",
        "  global_step = 0\n",
        "  train_loss_list = []\n",
        "  valid_loss_list = []\n",
        "  global_steps_list = []\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    for text, label in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "      padded_list = [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "      sample = torch.tensor(padded_list)\n",
        "      sample, label = sample.to(device), label.to(device)\n",
        "      labels = torch.tensor(label)\n",
        "      outputs = model(sample, labels=labels)\n",
        "      loss, logits = outputs\n",
        "\n",
        "      pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "      correct = pred.eq(labels)\n",
        "      total_correct += correct.sum().item()\n",
        "      total_len += len(labels)\n",
        "      running_loss += loss.item()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      global_step += 1\n",
        "\n",
        "      if global_step % eval_every == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "          for text, label in valid_loader:\n",
        "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "            padded_list = [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "            sample = torch.tensor(padded_list)\n",
        "            sample, label = sample, label = sample.to(device), label.to(device)\n",
        "            labels = torch.tensor(label)\n",
        "            ouputs = model(sample, labels=labels)\n",
        "            loss, logits = outputs\n",
        "            valid_running_loss += loss.item()\n",
        "        \n",
        "        average_train_loss = running_loss / eval_every\n",
        "        average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "        train_loss_list.append(average_train_loss)\n",
        "        valid_loss_list.append(average_valid_loss)\n",
        "        global_steps_list.append(global_step)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        valid_running_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "\n",
        "        print('Epoch [{}/{}], Step[{}/{}], Train Loss : {:.4f}, Valid Loss : {:.4f}'.format(epoch+1, \n",
        "                                                                                            num_epochs, \n",
        "                                                                                            global_step, \n",
        "                                                                                            num_epochs*len(train_loader), \n",
        "                                                                                            average_train_loss, \n",
        "                                                                                            average_valid_loss))\n",
        "        \n",
        "        if best_valid_loss > average_valid_loss:\n",
        "          best_valid_loss = average_valid_loss\n",
        "          save_checkpoint('./dataset/model.pt', model, best_valid_loss)\n",
        "          save_metrics('./dataset/metrics.pt', train_loss_list,\n",
        "                       valid_loss_list, global_steps_list)\n",
        "  save_metrics('./dataset/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "\n",
        "  print('훈련 종료!')"
      ],
      "metadata": {
        "id": "Tx7oO7o5ScZ2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "train(model=model, optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-EhJrUlaZKl",
        "outputId": "883b049d-cb5a-4522-9551-ba9aa8d8a586"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-fd5570383532>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(label)\n",
            "<ipython-input-29-fd5570383532>:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
            "<ipython-input-29-fd5570383532>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(label)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step[45/450], Train Loss : 0.4867, Valid Loss : 0.1475\n",
            "Epoch [1/5], Step[90/450], Train Loss : 0.5630, Valid Loss : 1.6577\n",
            "Epoch [2/5], Step[135/450], Train Loss : 0.5139, Valid Loss : 1.0850\n",
            "Epoch [2/5], Step[180/450], Train Loss : 0.4935, Valid Loss : 0.1963\n",
            "Epoch [3/5], Step[225/450], Train Loss : 0.5086, Valid Loss : 0.1723\n",
            "Epoch [3/5], Step[270/450], Train Loss : 0.5584, Valid Loss : 0.2512\n",
            "Epoch [4/5], Step[315/450], Train Loss : 0.4230, Valid Loss : 0.1866\n",
            "Epoch [4/5], Step[360/450], Train Loss : 0.6272, Valid Loss : 0.4996\n",
            "Epoch [5/5], Step[405/450], Train Loss : 0.5468, Valid Loss : 0.8187\n",
            "Epoch [5/5], Step[450/450], Train Loss : 0.5150, Valid Loss : 0.2268\n",
            "훈련 종료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list, valid_loss_list, global_steps_list = load_metrics('./dataset/metrics.pt')\n",
        "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "plt.xlabel('Global Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "fH5OQi2E5FoP",
        "outputId": "4490d7f1-a102-41ba-ae42-c8f9605ef3cb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== ./dataset/metrics.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "  y_pred = []\n",
        "  y_true = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for text, label in test_loader:\n",
        "      encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "      padded_list = [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "      sample = torch.tensor(padded_list)\n",
        "      sample, label = sample.to(device), label.to(device)\n",
        "      labels = torch.tensor(label)\n",
        "      output = model(sample, labels=labels)\n",
        "      _, output = output\n",
        "      y_pred.extend(torch.argmax(output, 1).tolist())\n",
        "      y_true.extend(labels.tolist())\n",
        "  \n",
        "  print('Classification 결과:')\n",
        "  print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
        "\n",
        "  cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
        "  ax = plt.subplot()\n",
        "  sns.heatmap(cm, annot=True, ax=ax, cmap='Blues', fmt=\"d\")\n",
        "  ax.set_title('Confusion Matrix')\n",
        "  ax.set_xlabel('Predicted Labels')\n",
        "  ax.set_ylabel('True Labels')\n",
        "  ax.xaxis.set_ticklabels(['0', '1'])\n",
        "  ax.yaxis.set_ticklabels(['0', '1'])\n"
      ],
      "metadata": {
        "id": "qU1QFD625qer"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = model.to(device)\n",
        "load_checkpoint('./dataset/model.pt', best_model)\n",
        "evaluate(best_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "1VbtvSqw-09U",
        "outputId": "74877c4b-dd57-4cc6-af4b-55d19f9514ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== ./dataset/model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-e3e74197ca51>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(label)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification 결과:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8529    1.0000    0.9206        29\n",
            "           0     0.0000    0.0000    0.0000         5\n",
            "\n",
            "    accuracy                         0.8529        34\n",
            "   macro avg     0.4265    0.5000    0.4603        34\n",
            "weighted avg     0.7275    0.8529    0.7852        34\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}